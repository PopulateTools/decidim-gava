<section id="uned-poll" class="uned-poll <%= request.path == "/" ? nil : 'is-hidden' %>">
  <section class="uned-poll-content">
    <button id="uned-poll-close-button">
      <img class="uned-poll-close-button-img" src="<%= asset_path 'close.svg' %>">
    </button>
    <article class="uned-poll-content-header">
      <img class="uned-poll-content-header-img" src="<%= asset_path 'uned-header-image.png' %>">
      <img class="uned-poll-content-header-logoimg" src="<%= asset_path 'logo-uned.png' %>">
    </article>

    <article class="uned-poll-content-medium">
      <h3 class="uned-poll-content-title">Consulta</h3>
      <!-- T1 Portada -->
      <!-- 2.1.1 -->
      <h5 class="uned-poll-content-subtitle ">Hacia un marco ético para el uso responsable de datos masivos</h5>
            <p class="uned-poll-content-text">
              La UNED, como parte de su respuesta pionera al reto tecnológico
              actual, se plantea el objetivo de utilizar los datos masivos para
              apoyar los procesos de enseñanza y aprendizaje a fin de ajustarlos a
              cada persona y hacerlos más útiles, amables y efectivos. Esto se ha
              hecho antes.
            </p>
            <p class="uned-poll-content-text">
              Sin embargo, como institución que quiere ser responsable y transparente con las consecuencias éticas y sociales que puede conllevar el uso de las tecnologías basadas en datos masivos, la UNED se propuso, por primera vez, definir de forma colectiva un marco ético que garantice un uso responsable de las mismas.
            </p>
            <p class="uned-poll-content-text">
              Para el diseño de este marco ético, se contó con la participación de toda la comunidad universitaria, y en este sitio puedes encontrar los resultados del proceso.
            </p>
      <!-- ./ 2.1.2 -->

      <!-- ./ 2.1.2 -->
      <!-- ./ T1 Portada -->

      <div class="uned-poll-content-table">
        <p class="uned-poll-content-table-text">
          La consulta estuvo abierta del 13 de enero al 26 de enero de 2020.
          Toda la comunidad de la UNED estuvo invitada a participar en el debate, y se generaron <a href="https://participa.uned.es/processes/uso-responsable-de-datos/f/98/">interesantes intervenciones.</a>
        </p>
        <p class="uned-poll-content-table-text">
          Además, al final del proceso se obtuvo un conjunto, ratificado por la comunidad, de cautelas necesarias para un uso responsable de las tecnologías basadas en datos masivos en la UNED. Estas cautelas definen nuestro marco ético para el uso de esas tecnologías. Accede al marco ético pinchando <a id="uned-poll-button-top-5" href="#marco-etico">aquí.</a>
        </p>
        <p class="uned-poll-content-table-text">
          <!-- //TODO: ENLACE AL PDF ???? -->
          También puedes acceder al <a href="#">análisis de la participación.</a>
        </p>
      </div>
      <!-- 2.1.2 -->
      <a class="uned-poll-accordion-child uned-poll-content-subtitle-accordion">El proyecto ED3: Educación a Distancia, Digital y apoyada en Datos</a>
      <div class="uned-poll-slider-content-accordion">
        <p class="uned-poll-content-text">
          ¿Te imaginas que la UNED acompaña tu proceso de aprendizaje adaptándolo de forma automática a tus ritmos, a tus necesidades, a tus intereses?
        </p>
        <p class="uned-poll-content-text">
          Esta personalización puede hacerse a través del uso de tecnologías basadas en datos masivos, y ese es el objetivo del Proyecto ED3 de la UNED. En otras palabras: el Proyecto ED3 aspira a desarrollar un marco de intervenciones basadas en evidencias para mejorar los procesos de enseñanza y aprendizaje a través de la explotación inteligente y responsable de datos.
        </p>
      </div>
    </article>

    <p class="uned-poll-contet-arrow-left-text">Te invitamos a que repases los materiales que hemos preparado para dar contexto a esta consulta.
      <img class="uned-poll-img-arrow-left" src="<%= asset_path 'arrow-left.svg' %>"></p>

    <article class="uned-poll-content-footer">
      <div class="uned-poll-content-buttons-top">
        <button id="uned-poll-button-top-1" class="uned-poll-buttons-top-slider is-active-btn">¿Qué son las TBDM?</button>
        <button id="uned-poll-button-top-2" class="uned-poll-buttons-top-slider">Antecedentes</button>
        <button id="uned-poll-button-top-3" class="uned-poll-buttons-top-slider">¿Hace falta un marco ético?</button>
        <a id="uned-poll-button-top-4" href="#marco-etico" class="uned-poll-buttons-top-slider">Marco ético</a>
      </div>

      <div class="uned-poll-slider-container-content">
        <!-- T2: Qué son las TBDM -->
        <div id="uned-poll-slider-content-text-1" class="uned-poll-slider-content">
          <!-- 2.2 [T2] Referentes y aproximaciones previas -->
          <h1 class="uned-poll-slider-content-title">¿QUÉ SON Y PARA QUÉ PUEDEN SERVIR EN LA UNED LAS TECNOLOGÍAS BASADAS EN DATOS MASIVOS?</h1>
          <p class="uned-poll-slider-content-text">Nuestras comunicaciones, nuestro entretenimiento, nuestras relaciones comerciales y nuestros aprendizajes suceden en la Web. Así, las compañías hacen uso de nuestros datos para afectarnos: nos recomiendan una película o un libro, nos sirven anuncios personalizados, nos ayudan a acordarnos de fechas importantes. Esta filosofía es de aplicación también en la enseñanza y el aprendizaje, y su fin es avanzar hacia escenarios de aprendizaje personalizado.</p>
          <p class="uned-poll-slider-content-text">Algunos ejemplos: es posible modelar de forma automática el conocimiento, el comportamiento o la experiencia del alumnado, es posible segmentarlo en perfiles que permitan adaptar los entornos de aprendizaje, es posible modelar los contenidos para extraer de forma automática las unidades de estudio o los conceptos clave, y su dificultad, así como es posible diseñar procesos de aprendizaje más efectivos a partir de los datos para responder a cuestiones como: ¿qué elementos son más efectivos para promover el aprendizaje?, ¿un cambio concreto en los contenidos o las metodologías puede mejorar el desempeño y la retención?, ¿qué tipo de metodologías son mejores en términos de la experiencia del alumnado?</p>
          <!-- ./ 2.2 [T2] Referentes y aproximaciones previas -->
        </div>
        <!-- ./ T2: Qué son las TBDM -->

        <!-- Antecedentes -->
        <div id="uned-poll-slider-content-text-2" class="uned-poll-slider-content is-hidden">
          <h1 class="uned-poll-slider-content-title">Referentes y aproximaciones previas</h1>

          <p class="uned-poll-slider-content-text">Experiencias previas: las que no</p>
          <p class="uned-poll-slider-content-text-list">El caso <a href="https://bits.blogs.nytimes.com/2014/04/21/inbloom-student-data-repository-to-close/">InBloom (2013, EEUUA)</a>: organización no gubernamental que atrajo inversiones millonarias (fundaciones Gates, Carnegie). Alarmó a defensores de la privacidad y a asociaciones de familiares del alumnado. Fue cancelado fulminantemente en 2014.</p>
          <p class="uned-poll-slider-content-text-list">El caso <a href="https://es.snappet.org/">Stichting Snappet (2014, Holanda)</a>: más de 400 escuelas públicas alquilaron tabletas con apps para aprender matemáticas y lengua. Los datos se usaban para clasificar y predecir el desempeño del alumnado, y para proponer intervenciones a los centros, lo cual llevó a las autoridades holandesas a abrir un expediente. En el informe final, se indicó que la empresa no había informado su cientemente y no había pedido consentimiento para el uso de los datos.</p>

          <p class="uned-poll-slider-content-text">Experiencias previas: las que si</p>
          <p class="uned-poll-slider-content-text-list"><a href="https://help.open.ac.uk/documents/policies/ethical-use-of-student-data">Reglamento de la Open University (Reino Unido) (2014)</a>: ocho  principios  (el uso de datos como práctica ética, responsabilidad, parcialidad de los datos, propósito y límites, transparencia, participación, solidez y control de sesgos).</p>
          <p class="uned-poll-slider-content-text-list"><a href="https://www.jisc.ac.uk/guides/code-of-practice-for-learning-analytics">Reglamento del Jisc</a>: <i>Code of practice for Learning Analytics (2014)</i>: responsabilidad, transparencia y consentimiento, privacidad, validez, acceso, intervenciones, evitación de impactos adversos, administración de los datos.</p>
          <p class="uned-poll-slider-content-text-list"><a href="https://www.icde.org/knowledge-hub/the-aim-of-the-guidelines-is-to-identify-which-core-principles-relating-to-ethics-are-core-to-all-and-where-there-is-legitimate-differentiation-due-to-separate-legal-or-more-broadly-cultural-environments">Directrices del Consejo Internacional para la Educación Abierta y a Distancia</a>: propiedad y control de los datos, transparencia, accesibilidad, validez y  fiabilidad, responsabilidad institucional, comunicación, valores culturales, inclusión, consentimiento, responsabilidad y agencia del alumnado.</p>

          <p class="uned-poll-slider-content-text">Otros proyectos relacionados: <a href="https://sheilaproject.eu/">SHEILA</a>, <a href="http://www.laceproject.eu/blog/ethics-privacy-in-learning-analytics-a-delicate-issue/">LACE</a>, <a href="http://leas-box.cognitive-science.at/">LEA's BOX</a>...</p>
        </div>
        <!-- ./ Antecedentes -->

        <!-- 2.3 [T3] Por qué hace falta un marco ético? -->
        <div id="uned-poll-slider-content-text-3" class="uned-poll-slider-content is-hidden">
          <h1 class="uned-poll-slider-content-title">¿HACE FALTA UN MARCO ÉTICO?</h1>
          <p class="uned-poll-slider-content-text">Sabemos que una cosa es cumplir la ley y otra  muy distinta  ser buenas personas. La UNED, como institución, está decidida a apostar por ambas.</p>
          <p class="uned-poll-slider-content-text">Pese a que las leyes actuales (LOPD y RGPD) están concebidas para proteger la privacidad, la UNED no quiere permanecer ajena a que, en ocasiones, se dan usos preocupantes de nuestros datos amparados por la ley: mecanismos automáticos de selección de personal aquejados de sesgos racistas, algoritmos de predicción de reincidencia en delitos que no respetan la presunción de inocencia, algoritmos de selección de aspirantes a asilo que deciden a partir de el acento de las personas...</p>

          <!-- 2.3.1 [T31] ¿Qué preguntas hay que hacerse antes de usar datos masivos? -->
          <a class="uned-poll-accordion-parent">¿Qué preguntas hay que hacerse antes de usar datos masivos?</a>
            <div class="uned-poll-slider-content-accordion">
            <a class="uned-poll-slider-content-accordion-title uned-poll-accordion-child">¿Quién puede beneficiarse?</a>
            <div class="uned-poll-slider-content-accordion">
              <p>Más allá de categorías genéricas como “la comunidad universitaria”, es esencial considerar qué agentes concretos pueden verse beneficiados en cada caso, y en qué condiciones. En algunas ocasiones el beneficio de una de las partes puede ser incompatible con el de otras. Porsupuesto, en tales casos, atendiendo a la ética de los cuidados considerada más arriba, se debe priorizar a las partes a priori más débiles. Además, es importante tener en cuenta lasconsecuencias que sobre aquellas personas que no se podrán beneficiar de estas tecnologías(alumnado en reclusión forzosa, con diversidad funcional o quienes no deseen que sus datossean usados, por ejemplo) puede tener su generalización.</p>
            </div>
            <a class="uned-poll-slider-content-accordion-title uned-poll-accordion-child">¿A quién puede poner en riesgo?</a>
            <div class="uned-poll-slider-content-accordion"><p>Además de considerar los beneficiarios, es importante identificar aquellos colectivos que pueden ser puestos en riesgo para poder calibrar los pros y los contras de cualquier intervención. Como es obvio, el riesgo será mayor para los colectivos más expuestos, que en elcaso de la UNED son el alumnado y, en menor medida, los equipos docentes y tutoriales.</p>
            <p>Para el primer colectivo, hay encuestas que indican que las tecnologías basadas en datos masivos suelen ser bien aceptadas, pero también que existen casos en que los efectos pueden ser perniciosos: por ejemplo, los mensajes reiterativos pueden inducir desmotivación en ciertas personas o las predicciones de abandono funcionar como profecías autocumplidas. Además, allí donde se usen datos demográficos y de formación previa, existe un potencial para la propagación de estereotipos, sesgos y discriminaciones basadas en características grupales.</p>
            <p>En cuanto a los equipos docentes y tutoriales, si las preguntas que guían el uso de las tecnologías basadas en datos masivos son fijadas por la administración educativa, sin aportes de dichos equipos, es fácil que se incremente el control gerencial sobre la enseñanza, con el foco centrado en la rendición de cuentas. En este sentido, el compromiso y la participación delprofesorado es crucial para asegurar la implementación exitosa de cualquier aplicación.</p></div>
            <a class="uned-poll-slider-content-accordion-title uned-poll-accordion-child">¿Quién toma las decisiones?</a>
            <div class="uned-poll-slider-content-accordion"><p>Dada la preocupación por el uso inadecuado de los datos, es necesario identificar en cada caso dónde reside la responsabilidad de fijar las preguntas que han de ser respondidas mediante el análisis de los datos, pero también qué datos se recolectan, analizan y visualizan, y quién tendrá acceso a qué información. Experiencias previas recomiendan que la comunidad afectada (el alumnado y los equipos docentes y tutoriales, por ejemplo) sean parte del proceso decisorio, es decir, que  no existan  procesos meramente informativos sino que sean vinculantes: que estén preparados para virar el rumbo si así lo decide la comunidad. Además, deberían establecerse  procedimientos formalizados que vayan más allá de recoger información mediante encuestas o participación en foros, por ejemplo utilizando metodologías de previsión de impacto o ingeniería de requisitos basada en la comunidad [<a href="https://www.aepd.es/media/guias/guia-evaluaciones-de-impacto-rgpd.pdf">Guía práctica para las evaluaciones de impacto en la protección de los datos sujetas al RGPD</a>].</p></div>
            <a class="uned-poll-slider-content-accordion-title uned-poll-accordion-child">¿Qué datos se ponen en juego?</a>
            <div class="uned-poll-slider-content-accordion"><p>Con la digitalización de cada vez más ámbitos de la vida cotidiana, incluyendo los procesos de enseñanza/aprendizaje, el volumen y la variedad de datos que pueden ser puestos en juego es cada vez mayor. Al mismo tiempo, las posibilidades de cometer errores y propagar sesgos se incrementan cuando los datos son parciales, no existentes o cuando se cruzan datos entre bases de datos diferentes. Las inexactitudes, sesgos e imprecisiones derivadas del proceso de tratamiento de los datos pueden tener consecuencias graves, por lo que se recomienda el acceso al mayor número de datos posibles. También es extremadamente delicado el uso potencial de fuentes de datos externas a la institución como las redes sociales, en las que se dan procesos de desvelamiento de identidad potencialmente incontrolados, que además descansan sobre políticas de compañías no necesariamente alineadas con los principios de la institución.</p></div>
            <a class="uned-poll-slider-content-accordion-title uned-poll-accordion-child">¿Quién necesita ser informado y qué necesita saber?</a>
            <div class="uned-poll-slider-content-accordion"><p>En el caso concreto de los procesos de enseñanza/aprendizaje, analógicos o digitales, es claro que dependen en todo caso de cierto nivel de cesión de información entre las partes. Esto es así también en otros ámbitos de digitalización. Sin embargo, el desarrollo de tecnologías basadas en datos masivos exige preguntarse hasta qué punto las instituciones tienen la obligación de informar a la comunidad del uso que se hace de sus datos y de que su comportamiento puede estar siendo hasta cierto punto monitorizado. Por ejemplo, ¿es necesario informar al alumnado de que se almacenan datos anónimos para calcular promedios de tiempo empleado en acabar una titulación? ¿Y si por el contrario se almacenan los datos depersonas concretas para el mismo fin?</p></div>
            <a class="uned-poll-slider-content-accordion-title uned-poll-accordion-child">¿Es necesario el consentimiento expreso para el uso de datos? ¿Cómo se otorga?</a>
            <div class="uned-poll-slider-content-accordion"><p>Más allá de informar de que hay datos que están siendo registrados, existe un debate abierto acerca de si el consentimiento expreso es necesario o no, y en caso de que sí, con qué frecuencia y en qué circunstancias. Algunos enfoques propuestos incluyen: aceptación de inclusión al inicio de la relación con posibilidad de decidir la autoexclusión más adelante; posibilidad de autoexclusión al inicio de la relación con posibilidad de inclusión más adelante; aceptación de inclusión al inicio de la relación y nueva aceptación de inclusión cada vez que haya cambios; aceptación de inclusión o posibilidad de exclusión cada vez que se desencadene una intervención basada en datos. La lista no es exhaustiva y cada enfoque tiene suspropias limitaciones.</p></div>
            <a class="uned-poll-slider-content-accordion-title uned-poll-accordion-child">¿Hasta qué punto son necesarias disposiciones de privacidad?</a>
            <div class="uned-poll-slider-content-accordion"><p>La privacidad, en el contexto actual, se ha convertido en un concepto polémico y resbaladizo. En este contexto, surgen preguntas acerca de qué datos se recopilan, quién puede ver información acerca de personas concretas (por ejemplo, ¿puede el profesorado ver información sobre el alumnado de cursos en los que no está involucrado?, pero también, ¿pueden otras instituciones?, ¿y futuros empleadores?) y cuánto tiempo es imprescindible mantener los datos accesibles, sabiendo que el uso de datos históricos de cursos pasados puede beneficiar al alumnado actual.</p></div>
            <a class="uned-poll-slider-content-accordion-title uned-poll-accordion-child">¿Es necesario desidentificar los datos? ¿Es esto suficiente para garantizar el anonimato?</a>
            <div class="uned-poll-slider-content-accordion"><p>Cuando el identificador personal es sustituido por un código arbitrario, decimos que los datos han sido desidentificados, y se espera que sea imposible reconocer a un individuo concreto a partir de los registros guardados. Sin embargo, cuando se juntan fuentes de datos diversas y detalladas (‘big data’), esta precaución no siempre es suficiente, lo cual ha provocado, en algunos casos célebres, consecuencias inesperadas (por ejemplo, es posible identificar a una persona en una base de datos anonimizada mediante información de redessociales). Estas consecuencias pueden ser evitadas con procesos de anonimización más robustos, pero, sin embargo, no siempre es posible (ni deseable) anonimizar datos durante el desarrollo de la relación entre la institución y los miembros de su comunidad, lo que supone, por ejemplo, que en ámbitos educativos los procesos de anonimización han de tener lugar una vez que el alumnado abandona la institución (o cuando fije la normativa).</p></div>
            <a class="uned-poll-slider-content-accordion-title uned-poll-accordion-child">¿Quién es responsable de la administración y la protección de los datos?</a>
            <div class="uned-poll-slider-content-accordion"><p>Es importante (y en algunos casos obligatorio) que la institución defina quién tiene la responsabilidad de la preservación, seguridad y compartición de los datos, incluyendo responsables concretos para la recolección, los procesos de anonimización, los análisis y la administración de los datos, al menos.</p></div>
            <a class="uned-poll-slider-content-accordion-title uned-poll-accordion-child">¿Quién posee los datos y cuáles son las implicaciones?</a>
            <div class="uned-poll-slider-content-accordion"><p>Determinar los derechos de propiedad intelectual de los datos y los resultados obtenidos apartir de ellos es un asunto de gran complejidad y repercusiones: ¿pertenecen a cada individuo, a la institución, a la compañía que provee la infraestructura? ¿Pueden usarse en investigación? ¿Cómo afecta esto a la posibilidad de reutilización de datos fuera de la UNED, si tal cosa llega a ser planteada?</p></div>
            <a class="uned-poll-slider-content-accordion-title uned-poll-accordion-child">¿Tiene la UNED alguna obligación de actuar?</a>
            <div class="uned-poll-slider-content-accordion"><p>Si se demuestra que las tecnologías basadas en datos masivos conllevan beneficios, como por ejemplo incrementar el éxito del alumnado, ¿tiene la institución la obligación de intervenir para sacar partido de esta oportunidad? Esta obligación, ¿qué relación guarda con el coste económico que dicha intervención pueda tener? Es decir, ¿es admisible que la UNED no actúe a sabiendas de que el alumnado puede beneficiarse, por ejemplo?</p></div>
            <a class="uned-poll-slider-content-accordion-title uned-poll-accordion-child">¿Cómo puede ser reconocida y respetada la voluntad de los miembros de la comunidad universitaria?</a>
            <div class="uned-poll-slider-content-accordion"><p>Si las tecnologías basadas en datos masivos sugieren alguna acción concreta, es necesario definir si las personas afectadas están o no obligadas a aceptarla, y cuáles son las consecuencias de una u otra elección. Existe un cierto riesgo de infantilización a través de la coerción y las invasiones de la privacidad.</p></div>
            <a class="uned-poll-slider-content-accordion-title uned-poll-accordion-child">Si algo sale mal, ¿qué posibilidades de reparación existen?</a>
            <div class="uned-poll-slider-content-accordion"><p>Reconociendo que las tecnologías basadas en datos masivos pueden tener consecuencias imprevistas, es necesario preguntarse acerca de las capacidades de reparación de las que la institución quiere dotarse. Dar la posibilidad de que cualquiera pueda formular objeciones o quejas por un canal institucional claro es un paso esencial para abordar repercusiones inesperadas.</p></div>
            <a class="uned-poll-slider-content-accordion-title uned-poll-accordion-child">¿No está todo esto cubierto por la normativa vigente?</a>
            <div class="uned-poll-slider-content-accordion"><p>Pese a que la reforma europea de 2016 de las <a href="http://data.europa.eu/eli/reg/2016/679/oj/spa" target="_blank">reglas de protección de datos</a> ha supuesto un gran avance en la protección del control individual sobre los datos personales y en la especificación de reglas para instituciones y empresas, no faltan voces críticas que alertan de sus limitaciones en la <a href="https://www.abc.es/tecnologia/redes/abci-rgpd-mejor-y-peor-nueva-normativa-privacidad-segun-expertos-201805242219_noticia.html" target="_blank">protección de la privacidad</a>. Además, son notorios los casos de empresas que, cumpliendo escrupulosamente con la legalidad, han incurrido en prácticas más que cuestionables. Mediante esta consulta, la UNED pretende ir más allá y establecer un marco ético que, dentro del más escrupuloso respeto por la normativa vigente, proporcione mayor seguridad y tranquilidad a los miembros de su comunidad.</p></div></div>
          <!-- ./ 2.3.1 [T31] -->

          <!-- 2.3.2 [T32] Hacia una ética del cuidado -->
          <a class="uned-poll-accordion-parent">Hacia una ética del cuidado</a>
          <div class="uned-poll-slider-content-accordion">
          <p class="uned-poll-slider-content-text"><b>datum vs. captum</b>: Dato proviene del latín datum, aquello que es dado. Sin embargo, puesto que en el contexto tecnológico actual la mayor parte de los datos son tomados antes que dados, quizá sería más lógico hablar de captum: aquello que es apresado o capturado.</p>
          <a class="uned-poll-slider-content-accordion-title uned-poll-accordion-child">Una ética del cuidado se orienta a:</a>
          <div class="uned-poll-slider-content-accordion">
            <p>Tener cuidado con nuestras presunciones acerca de las evidencias que aportan los datos, así como las que hacemos acerca de la naturaleza y el uso de estos, acerca de su gobernanza, de la privacidad y del acceso a los mismos, y a cuidar del alumnado y recopilar, analizar y utilizar sus datos para mejorar sus tasas de éxito y de retención.</p>
          </div>
          </div>

          <!-- ./ 2.3.2 [T32] -->

          <!-- 2.3.3 [T33] Vídeo: Datos masivos y ética: ¿es suficiente la legislación actual? -->
          <a class="uned-poll-accordion-parent">Conferencia invitada: Datos masivos y ética: ¿es suficiente la legislación actual?</a>
          <div class="uned-poll-slider-content-accordion">
            <p>En esta conferencia, que tuvo lugar el 3 de diciembre de 2019 en el Programa de Doctorado en Sistemas Inteligentes, la investigadora Manuela Battaglini explora las limitaciones de la legislación actual y pone de relieve los riesgos que tales limitaciones suponen para el uso ético de los datos masivos.</p>
          <a class="uned-poll-slider-content-accordion-title uned-poll-accordion-child">Vídeo</a>
          <div class="uned-poll-slider-content-accordion">
            <div class="iframe-container">
              <iframe src="https://canal.uned.es/iframe/magic/c55zi7ftmxkc88oc8ccco4gc4ckco8c"
                      id="pumukitiframe" frameborder="0" border="0" width="840" height="473" allowfullscreen>
              </iframe>
            </div>
          </div>
          </div>

          <!-- ./ 2.3.3 [T33] -->
        </div>
        <!-- ./ 2.3 [T3] -->

        <div id="uned-poll-slider-content-text-4" class="uned-poll-slider-content is-hidden">
          <h1 class="uned-poll-slider-content-title">Marco ético para el uso responsable de datos masivos</h1>
          <p class="uned-poll-slider-content-text">La UNED, como parte de su respuesta pionera al reto tecnológico actual, se plantea el objetivo de utilizar los datos masivos para apoyar los procesos de enseñanza y aprendizaje a fin de ajustarlos a cada persona y hacerlos más útiles, amables y efectivos. A la vez, como institución que quiere ser responsable y transparente con las consecuencias éticas y sociales que puede conllevar el uso de las tecnologías basadas en datos masivos, propuso, por primera vez, definir junto a la comunidad universitaria un marco ético que garantice un uso responsable de las mismas. Fruto de ese proceso de deliberación colectiva es este conjunto de cautelas, ordenadas en función del nivel de apoyo recibido, que definen el marco ético para el uso de datos masivos en la UNED:</p>

          <h1 class="uned-poll-slider-content-title-cautela">Cautela 0: Del cuidado</h1>
          <p class="uned-poll-slider-content-text">Una voluntad expresa de cuidado guiará en todo momento las actuaciones de la UNED respecto al uso de los datos: tendrá cuidado de que no se haga un mal uso de ellos (primum nil nocere) y cuidará, a través de ellos, del bienestar de los miembros de la comunidad universitaria, particularmente del de los colectivos más vulnerables.</p>

          <h1 class="uned-poll-slider-content-title-cautela">Cautela 1: De la responsabilidad</h1>
          <p class="uned-poll-slider-content-text">La UNED asume su responsabilidad en el uso de datos y determinará una autoridad reconocible que será responsable del uso legal, ético y eficiente de las tecnologías basadas en datos. Además, será necesario fijar quién tiene responsabilidades específicas sobre la anonimización de los datos así como su recolección, conservación y administración.</p>

          <h1 class="uned-poll-slider-content-title-cautela">Cautela 2: De la transparencia</h1>
          <p class="uned-poll-slider-content-text">La UNED desarrollará políticas institucionales claras con respecto al uso de tecnologías basadas en datos masivos. Definirá, registrará y comunicará a la comunidad universitaria las fuentes de datos, los propósitos de los análisis, las métricas usadas, quién tiene acceso a los análisis, los límites de su uso y cómo se interpretan los datos. Cuando los datos estén incompletos o se usen como aproximación a otros no disponibles, se aclarará en qué suposiciones se basa dicha aproximación.</p>

          <h1 class="uned-poll-slider-content-title-cautela">Cautela 3: Del consentimiento</h1>
          <p class="uned-poll-slider-content-text">El consentimiento de cada miembro de la comunidad universitaria será necesario para el uso de sus datos personales. Si el consentimiento se da al inicio de la relación con la UNED, será informado con explicaciones detalladas acerca del uso previsto de los datos. Cuando los datos se usen para intervenir en las decisiones que afectan al trayecto de una persona en el seno de la institución o al acceso a sus recursos, será necesario obtener consentimiento expreso y específico para esos usos. La UNED establecerá protocolos para permitir la revocación del consentimiento.</p>

          <h1 class="uned-poll-slider-content-title-cautela">Cautela 4: De la propiedad y el control</h1>
          <p class="uned-poll-slider-content-text">La UNED asume que no es la propietaria de los datos personales recabados, sino solo la responsable temporal de su tratamiento. Conforme a las prácticas indicadas por la Agencia Española de Protección de Datos en cumplimiento del Reglamento Europeo de Protección de Datos, la UNED cuidará de que los miembros de su comunidad tengan la posibilidad de corregir, eliminar o añadir contexto a sus datos siempre que sea posible, así como la de acceder a los análisis derivados y la de reclamar ante posibles consecuencias adversas del uso de tecnologías basadas en datos.</p>

          <h1 class="uned-poll-slider-content-title-cautela">Cautela 5: De la validez y la fiabilidad</h1>
          <p class="uned-poll-slider-content-text">Para asegurar que las aplicaciones de tecnologías basadas en datos son válidas y fiables, la UNED garantizará que los datos son precisos y representativos de aquello que dicen medir. Además, serán mantenidos al día tanto como sea posible. Cuando en el análisis se usen encuestas de opinión o se apliquen inferencias estadísticas, la UNED cuidará de que la muestra sea suficientemente grande y representativa y de que los resultados sean estadísticamente significativos. Todos los algoritmos y métricas utilizados serán comprendidos, validados, revisados y mejorados según corresponda por personal calificado.</p>

          <h1 class="uned-poll-slider-content-title-cautela">Cautela 6: De la participación</h1>
          <p class="uned-poll-slider-content-text">Siempre que sea posible, la UNED tratará de involucrar a los distintos colectivos de la comunidad universitaria en la aplicación de tecnologías basadas en datos. En particular, dadas las relaciones asimétricas de poder en relación con el alumnado, otros colectivos de la UNED tratarán a sus miembros como iguales en lo relativo a los usos de sus datos, cuidando de que su punto de vista sea tenido en cuenta en la toma de decisiones.</p>

          <h1 class="uned-poll-slider-content-title-cautela">Cautela 7: De la privacidad y el acceso</h1>
          <p class="uned-poll-slider-content-text">El acceso a los datos y a los análisis derivados de ellos estará restringido a quienes tengan una causa legítima, que será determinada por la UNED en función del nivel de agregación de los datos y las competencias de quienes lo soliciten. Cuando los datos sean anónimos, la UNED cuidará de que no sea posible reidentificar a los individuos a partir de los metadatos ni por agregación de múltiples fuentes de datos. La UNED tendrá particular cuidado, en el caso de que los datos sean cedidos a terceras partes, de que estas se adhieran a las cautelas aquí expresadas y a los principios de la institución, evitando particularmente usos comerciales.</p>

          <h1 class="uned-poll-slider-content-title-cautela">Cautela 8: De los posibles impactos adversos</h1>
          <p class="uned-poll-slider-content-text">La UNED reconoce que cualquier individuo es siempre más que la suma de los datos disponibles acerca de ella o él, y que las circunstancias personales no pueden ser descritas totalmente por los datos. Así, tomará medidas para evitar que tendencias, promedios, categorías o etiquetas produzcan sesgos en la percepción de la institución sobre las personas o en su relación con ellas, así como que se refuercen actitudes discriminatorias o se incrementen las desigualdades. Además, el impacto de las intervenciones basadas en datos sobre los distintos colectivos de la comunidad universitaria será tenido en cuenta, particularmente en las necesidades de formación y en la carga de trabajo. En cualquier caso, la UNED hará lo que esté en su mano por minimizar los posibles impactos adversos.</p>

          <h1 class="uned-poll-slider-content-title-cautela">Cautela 9: De la comunicación efectiva</h1>
          <p class="uned-poll-slider-content-text">La UNED, en el caso de que, a pesar de sus esfuerzos, no pueda evitar el mal uso de la información de datos de algún miembro o colectivo de la Universidad, una vez detectado y subsanado el uso indebido, debe informar a los afectados de forma clara y en el menor tiempo posible.</p>

          <h1 class="uned-poll-slider-content-title-cautela">Cautela 10: De la discapacidad</h1>
          <p class="uned-poll-slider-content-text">La UNED tendrá especial cuidado en el tratamiento de los datos referidos al colectivo específico de estudiantes con discapacidad. Los datos referidos a la discapacidad son especialmente sensibles, en tanto que son de carácter médico y muy personal: por ello deben ser tratados de forma específica y diferenciada. Para ello, UNIDIS tendrá representación en el organismo o unidad que se encargue de velar por el correcto tratamiento de esos datos.</p>

          <h1 class="uned-poll-slider-content-title-cautela">Cautela 11: De la adaptabilidad</h1>
          <p class="uned-poll-slider-content-text">La UNED está interesada en adaptarse de forma adecuada a las realidades tecnosociales imperantes en cada momento, y velará por que este marco ético y las normas derivadas de él sean revisadas conforme los cambios en la tecnología, que se producen a gran velocidad, lo hagan necesario.</p>

          <h1 class="uned-poll-slider-content-title-cautela">Cautela 12: Del derecho a la explicación</h1>
          <p class="uned-poll-slider-content-text">La UE y otras instituciones proponen el derecho a la explicación respecto de las decisiones automatizadas como un derecho básico ante las tecnologías basadas en datos. Así, la UNED velará por que, allí donde se usen los datos masivos para tomar decisiones de forma automática que puedan afectar a cualquier miembro de la comunidad, estas decisiones sean explicadas de la forma más clara posible.</p>
        </div>

        <%= render "care_proposals/navigation" %>
      </div>
    </article>
  </section>
</section>
